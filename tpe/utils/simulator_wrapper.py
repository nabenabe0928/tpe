""" A collection of utilities for a simulation of multi-fidelity optimizations.

In multi-fidelity optimizations, as we often evaluate configs in parallel,
it is essential to manage the order of config allocations to each worker.
We allow such appropriate allocations with the utilities in this file.
To guarantee the safety, we share variables with each process using the file system.
Each file is protected by a token and it strictly prohibits more than one processes access to each file simaltaneously.

We first define some terminologies:
* simulator: A system that manages simulated runtimes to allow optimizations of a tabular/surrogate benchmark
             without waiting for actual runtimes.
* worker: Worker instantiates an objective function with a given config and evaluates it.
* proc: Each worker will be instantiated in each process.
* worker_id: The time hash generated for each worker.
* pid or proc_id: The process ID for each proc obtained by `os.getpid()`, which is an integer.
* index: The index of each worker. (it will be one of the integers in [0, N - 1] where N is the # of workers.)
* token: Each process has a unique token and each process can access to each file
         only if the token exists in the file system.

Now we describe each file shared with each process.
Note that each file takes the json-dict format and we write down as follows:
    * key1 -- val1
    * key2 -- val2
    :
    * keyN -- valN

1. simulator_info/*/proc_alloc.json
    * proc1_id -- worker1_id
    * proc2_id -- worker2_id
    :
    * procN_id -- workerN_id
Note that we need this file only if we have multiple processes in one run.
For example, when we use multiprocessing, we might need it.
`procX_id` is fetched by `os.getpid()` and `workerX_id` is initially generated by `generate_time_hash()`.

2. simulator_info/*/results.json
    * loss -- List[loss at the n-th evaluation]
    * cumtime -- List[cumtime up to the n-th evaluation]
    * index -- List[the index of the worker of the n-th evaluation]
This file is necessary for post-hoc analysis.

3. simulator_info/*/runtime_cache.json
    * config1 -- List[runtimes]
    * config2 -- List[runtimes]
    :
    * configN -- List[runtimes]
This file tells you how long it took to evaluate configX up to the intermediate result.
Since we would like to use this information only for the restart of trainings,
we discard the information after each config reaches the full-budget training.
Each list gets more than two elements if evaluations of the same configs happen.

4. simulator_info/*/simulated_cumtime.json
    * worker1_id -- cumtime1
    * worker2_id -- cumtime2
    :
    * workerN_id -- cumtimeN
This file tells you how much time each worker virtually spends in the simulation
and we need this information to manage the order of job allocations to each worker.
"""
import fcntl
import glob
import hashlib
import os
import time
from multiprocessing import Pool
from typing import Any, Callable, Dict, List, Protocol

import numpy as np

import ujson as json


DIR_NAME = "simulator_info/"
TOKEN_PATTERN = "simulator_*.token"
PUBLIC_TOKEN_NAME = "simulator.token"
WORKER_CUMTIME_FILE_NAME = "simulated_cumtime.json"
RESULT_FILE_NAME = "results.json"
PROC_ALLOC_NAME = "proc_alloc.json"
RUNTIME_CACHE_FILE_NAME = "runtime_cache.json"
INF = 1 << 40


def generate_time_hash() -> str:
    hash = hashlib.sha1()
    hash.update(str(time.time()).encode("utf-8"))
    return hash.hexdigest()


def publish_token(public_token: str, private_token: str, waiting_time: float = 1e-4) -> None:
    start = time.time()
    waiting_time *= 1 + np.random.random()
    while True:
        try:
            os.rename(public_token, private_token)
            return
        except FileNotFoundError:
            time.sleep(waiting_time)
            if time.time() - start >= 10:
                raise TimeoutError("Timeout during token publication. Please remove token files and try again.")


def remove_token(public_token: str, private_token: str) -> None:
    os.rename(private_token, public_token)


def verify_token(func: Callable) -> Callable:
    def _inner(public_token: str, private_token: str, **kwargs):
        publish_token(public_token=public_token, private_token=private_token)
        output = func(public_token=public_token, private_token=private_token, **kwargs)
        remove_token(public_token=public_token, private_token=private_token)
        return output

    return _inner


def init_token(token_pattern: str, public_token: str) -> None:
    n_tokens = len(glob.glob(token_pattern))
    if n_tokens == 0:
        with open(public_token, mode="w"):
            pass
    elif n_tokens > 1:  # Token from another process could exist!
        raise FileExistsError


def init_simulator(dir_name: str) -> None:
    for fn in [WORKER_CUMTIME_FILE_NAME, RESULT_FILE_NAME, RUNTIME_CACHE_FILE_NAME, PROC_ALLOC_NAME]:
        path = os.path.join(dir_name, fn)
        with open(path, "a+") as f:
            fcntl.flock(f.fileno(), fcntl.LOCK_EX)
            f.seek(0)
            content = f.read()
            if len(content) < 2:
                f.seek(0)
                f.truncate()
                f.write("{}")

            fcntl.flock(f.fileno(), fcntl.LOCK_UN)


def allocate_proc_to_worker(dir_name: str, pid: int) -> None:
    path = os.path.join(dir_name, PROC_ALLOC_NAME)
    with open(path, "r+") as f:
        try:
            fcntl.flock(f, fcntl.LOCK_EX)
            cur_alloc = json.load(f)
            cur_alloc[pid] = 0
            f.seek(0)
            json.dump(cur_alloc, f, indent=4)
            f.truncate()
        except IOError:
            pass
        finally:
            fcntl.flock(f, fcntl.LOCK_UN)


@verify_token
def complete_proc_allocation(public_token: str, private_token: str, dir_name: str) -> Dict[int, int]:
    path = os.path.join(dir_name, PROC_ALLOC_NAME)
    alloc = json.load(open(path))
    sorted_pids = np.sort([int(pid) for pid in alloc.keys()])
    alloc = {pid: idx for idx, pid in enumerate(sorted_pids)}
    with open(path, mode="w") as f:
        json.dump(alloc, f, indent=4)

    return alloc


@verify_token
def record_cumtime(public_token: str, private_token: str, worker_id: str, runtime: float, dir_name: str) -> float:
    path = os.path.join(dir_name, WORKER_CUMTIME_FILE_NAME)
    record = json.load(open(path))
    cumtime = record.get(worker_id, 0.0) + runtime
    record[worker_id] = cumtime
    with open(path, mode="w") as f:
        json.dump(record, f, indent=4)

    return cumtime


@verify_token
def cache_runtime(
    public_token: str, private_token: str, config_key: str, runtime: float, dir_name: str, update: bool = True
) -> None:
    path = os.path.join(dir_name, RUNTIME_CACHE_FILE_NAME)
    cache = json.load(open(path))
    if config_key not in cache:
        cache[config_key] = [runtime]
    elif update:
        cache[config_key][0] = runtime
    else:
        cache[config_key].append(runtime)

    cache[config_key] = np.sort(cache[config_key]).tolist()
    with open(path, mode="w") as f:
        json.dump(cache, f, indent=4)


@verify_token
def delete_runtime(public_token: str, private_token: str, config_key: str, index: float, dir_name: str) -> None:
    path = os.path.join(dir_name, RUNTIME_CACHE_FILE_NAME)
    cache = json.load(open(path))
    n_configs = len(cache.get(config_key, [])) > 0
    if n_configs <= 1:
        cache[config_key] = [0.0]  # we need to have at least one element.
    else:
        cache[config_key].pop(index)

    with open(path, mode="w") as f:
        json.dump(cache, f, indent=4)


@verify_token
def fetch_cache_runtime(public_token: str, private_token: str, dir_name: str) -> None:
    path = os.path.join(dir_name, RUNTIME_CACHE_FILE_NAME)
    return json.load(open(path))


@verify_token
def record_result(
    public_token: str, private_token: str, results: Dict[str, float], dir_name: str
) -> None:
    path = os.path.join(dir_name, RESULT_FILE_NAME)
    record = json.load(open(path))
    for key, val in results.items():
        if key not in record:
            record[key] = [val]
        else:
            record[key].append(val)

    with open(path, mode="w") as f:
        json.dump(record, f, indent=4)


@verify_token
def is_simulator_terminated(public_token: str, private_token: str, dir_name: str, max_evals: int) -> bool:
    path = os.path.join(dir_name, RESULT_FILE_NAME)
    return len(json.load(open(path))["loss"]) >= max_evals


@verify_token
def is_simulator_ready(public_token: str, private_token: str, n_workers: int, dir_name: str) -> bool:
    path = os.path.join(dir_name, WORKER_CUMTIME_FILE_NAME)
    return len(json.load(open(path))) == n_workers


@verify_token
def is_allocation_ready(public_token: str, private_token: str, n_workers: int, dir_name: str) -> bool:
    path = os.path.join(dir_name, PROC_ALLOC_NAME)
    return len(json.load(open(path))) == n_workers


@verify_token
def get_worker_id_to_idx(public_token: str, private_token: str, dir_name: str) -> Dict[str, int]:
    path = os.path.join(dir_name, WORKER_CUMTIME_FILE_NAME)
    return {worker_id: idx for idx, worker_id in enumerate(json.load(open(path)).keys())}


@verify_token
def is_min_cumtime(public_token: str, private_token: str, worker_id: str, dir_name: str) -> bool:
    path = os.path.join(dir_name, WORKER_CUMTIME_FILE_NAME)
    cumtimes = json.load(open(path))
    proc_cumtime = cumtimes[worker_id]
    return min(cumtime for cumtime in cumtimes.values()) == proc_cumtime


def wait_proc_allocation(
    public_token: str, private_token: str, n_workers: int, dir_name: str, waiting_time: float = 1e-2
) -> Dict[int, int]:
    start = time.time()
    kwargs = dict(public_token=public_token, private_token=private_token, dir_name=dir_name)
    waiting_time *= 1 + np.random.random()
    while True:
        if is_allocation_ready(**kwargs, n_workers=n_workers):
            return complete_proc_allocation(**kwargs)
        else:
            time.sleep(waiting_time)
            if time.time() - start >= n_workers * 0.5:
                raise TimeoutError("Timeout in the allocation of procs. Please make sure n_workers is correct.")


def wait_all_workers(
    public_token: str, private_token: str, n_workers: int, dir_name: str, waiting_time: float = 1e-2
) -> Dict[str, int]:
    start = time.time()
    kwargs = dict(public_token=public_token, private_token=private_token, dir_name=dir_name)
    waiting_time *= 1 + np.random.random()
    while True:
        if is_simulator_ready(**kwargs, n_workers=n_workers):
            return get_worker_id_to_idx(**kwargs)
        else:
            time.sleep(waiting_time)
            if time.time() - start >= n_workers * 5:
                raise TimeoutError("Timeout in creating a simulator. Please make sure n_workers is correct.")


def wait_until_next(
    public_token: str, private_token: str, worker_id: str, dir_name: str, waiting_time: float = 1e-4
) -> None:
    waiting_time *= 1 + np.random.random()
    kwargs = dict(public_token=public_token, private_token=private_token, worker_id=worker_id, dir_name=dir_name)
    while True:
        if is_min_cumtime(**kwargs):
            return
        else:
            time.sleep(waiting_time)


class ObjectiveFunc(Protocol):
    def __call__(self, eval_config: Dict[str, Any], budget: int) -> Dict[str, float]:
        raise NotImplementedError


class WorkerFunc:
    def __init__(
        self,
        subdir_name: str,
        n_workers: int,
        func: ObjectiveFunc,
        max_budget: int,
        loss_key: str = "loss",
        runtime_key: str = "runtime",
    ):
        worker_id = generate_time_hash()
        dir_name = os.path.join(DIR_NAME, subdir_name)
        public_token = os.path.join(dir_name, PUBLIC_TOKEN_NAME)
        private_token = os.path.join(dir_name, f"simulator_{worker_id}.token")
        os.makedirs(dir_name, exist_ok=True)
        token_pattern = os.path.join(dir_name, TOKEN_PATTERN)
        init_token(token_pattern=token_pattern, public_token=public_token)

        self._kwargs = dict(public_token=public_token, private_token=private_token, dir_name=dir_name)
        init_simulator(dir_name=dir_name)

        record_cumtime(**self._kwargs, worker_id=worker_id, runtime=0.0)
        self._func = func
        self._max_budget = max_budget
        self._runtime_key = runtime_key
        self._loss_key = loss_key
        self._terminated = False
        self._worker_id = worker_id
        self._worker_id_to_index = wait_all_workers(
            public_token=public_token, private_token=private_token, n_workers=n_workers, dir_name=dir_name
        )
        time.sleep(1e-2)  # buffer before the optimization
        self._index = self._worker_id_to_index[self._worker_id]
        self._prev_timestamp = time.time()

    def __repr__(self) -> str:
        return f"Worker-{self._worker_id}"

    def _get_cached_runtime_index(self, cached_runtimes: List[float], config_key: str, runtime: float) -> int:
        # a[i-1] < v <= a[i]: np.searchsorted(..., side="left")
        idx = np.searchsorted(cached_runtimes, runtime, side="left")
        return max(0, idx - 1)

    def _proc_output(self, eval_config: Dict[str, Any], budget: int) -> Dict[str, float]:
        output = self._func(eval_config, budget)
        config_key = str(eval_config)
        loss, total_runtime = output[self._loss_key], output[self._runtime_key]
        cached_runtimes = fetch_cache_runtime(**self._kwargs).get(config_key, [0.0])
        cached_runtime_index = self._get_cached_runtime_index(cached_runtimes, config_key, total_runtime)
        cached_runtime = cached_runtimes[cached_runtime_index]

        actual_runtime = max(0.0, total_runtime - cached_runtime)
        # Start from the intermediate result, and hence we overwrite the cached runtime
        overwrite_min_runtime = cached_runtime < total_runtime
        if budget != self._max_budget:  # update the cache data
            cache_runtime(**self._kwargs, config_key=config_key, runtime=total_runtime, update=overwrite_min_runtime)
        else:
            delete_runtime(**self._kwargs, config_key=config_key, index=cached_runtime_index)

        return {self._loss_key: loss, self._runtime_key: actual_runtime}

    def __call__(self, eval_config: Dict[str, Any], budget: int) -> Dict[str, float]:
        if self._terminated:
            return {self._loss_key: INF, self._runtime_key: INF}

        sampling_time = time.time() - self._prev_timestamp
        output = self._proc_output(eval_config, budget)
        loss, runtime = output[self._loss_key], output[self._runtime_key]
        cumtime = record_cumtime(**self._kwargs, worker_id=self._worker_id, runtime=runtime+sampling_time)
        wait_until_next(**self._kwargs, worker_id=self._worker_id)
        self._prev_timestamp = time.time()
        row = dict(loss=loss, cumtime=cumtime, index=self._index)
        record_result(**self._kwargs, results=row)
        return output

    def finish(self) -> None:
        record_cumtime(**self._kwargs, worker_id=self._worker_id, runtime=INF)
        self._terminated = True


class CentralWorker:
    def __init__(
        self,
        obj_func: ObjectiveFunc,
        n_workers: int,
        max_budget: int,
        max_evals: int,
        subdir_name: str,
        loss_key: str = "loss",
        runtime_key: str = "runtime",
    ):
        kwargs = dict(
            func=obj_func,
            n_workers=n_workers,
            subdir_name=subdir_name,
            max_budget=max_budget,
            loss_key=loss_key,
            runtime_key=runtime_key,
        )
        pool = Pool()
        results = []
        for _ in range(n_workers):
            time.sleep(5e-3)
            results.append(pool.apply_async(WorkerFunc, kwds=kwargs))

        pool.close()
        pool.join()
        self._loss_key = loss_key
        self._runtime_key = runtime_key
        self._max_evals = max_evals
        self._workers = [result.get() for result in results]
        self._dir_name = self._workers[0]._kwargs["dir_name"]
        self._public_token = self._workers[0]._kwargs["public_token"]
        self._n_workers = n_workers
        self._pid_to_index: Dict[int, int] = {}

    def _token_verification_kwawrgs(self, pid: int) -> Dict[str, str]:
        private_token = f"_{pid}.".join(self._public_token.split("."))
        kwargs = dict(public_token=self._public_token, private_token=private_token, dir_name=self._dir_name)
        return kwargs

    def _init_alloc(self, pid: int) -> None:
        kwargs = self._token_verification_kwawrgs(pid)
        allocate_proc_to_worker(self._dir_name, pid=pid)
        self._pid_to_index = wait_proc_allocation(**kwargs, n_workers=self._n_workers)

    def __call__(self, eval_config: Dict[str, Any], budget: int) -> Dict:
        pid = os.getpid()
        if len(self._pid_to_index) != self._n_workers:
            self._init_alloc(pid)

        worker_index = self._pid_to_index[pid]
        output = self._workers[worker_index](eval_config, budget)
        kwargs = self._token_verification_kwawrgs(pid)
        if is_simulator_terminated(**kwargs, max_evals=self._max_evals):
            self._workers[worker_index].finish()

        return output
